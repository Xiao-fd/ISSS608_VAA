---
title: "chinavis_01"
---

# **5. Getting Started**

## **5.1 Loading R packages**

We load the following R packages using the `pacman::p_load()` function:

```{r}
pacman::p_load(geojsonR,rjson,sf, dplyr,tidyr,stringr,readr,fs,purrr,ggplot2, plotly, ggstatsplot,igraph,lubridate,hms, vcd, ggalluvial, ggforce)

```

## **5.2 Importing data**

The code chunk below imports the dataset into R environment by using [*`read_csv()`*](https://readr.tidyverse.org/reference/read_delim.html) function of [`readr`](https://readr.tidyverse.org/) package. **readr** is one of the tidyverse package.

Read the individual CSV files into data frames. Check that the structure of each data frame is the same.

```{r}
df_TitleInfo <- read_csv("data/Data_TitleInfo.csv")
```

```{r}
df_StudentInfo <- read_csv("data/Data_StudentInfo.csv")
```

```{r}
csv_file_list <- dir('data/Data_SubmitRecord')
csv_file_list <- paste0("./data/Data_SubmitRecord/",csv_file_list)


df_StudentRecord <- NULL
for (file in csv_file_list) { # for every file...
  file <- read_csv(file)
    df_StudentRecord <- rbind(df_StudentRecord, file) # then stick together by rows
}
df_StudentRecord %>% glimpse()
```

```{R}
#| warning: false

#Find the number of missing values for each col
colSums(is.na(df_StudentInfo))
```

```{R}
#| warning: false

#Find the number of missing values for each col
colSums(is.na(df_TitleInfo))
```

```{R}
#| warning: false

#Find the number of missing values for each col
colSums(is.na(df_StudentRecord))

```

```{r}
# Step 1: Identify students with multiple classes
students_multiple_classes <- df_StudentRecord %>%
  group_by(student_ID) %>%
  summarise(unique_classes = n_distinct(class)) %>%
  filter(unique_classes > 1)

# Step 2: Identify the correct class for each student (the class with the highest frequency)
correct_classes <- df_StudentRecord %>%
  filter(student_ID %in% students_multiple_classes$student_ID) %>%
  group_by(student_ID, class) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  slice(1) %>%
  select(student_ID, correct_class = class)

# Step 3: Replace wrong class values
df_StudentRecord <- df_StudentRecord %>%
  left_join(correct_classes, by = "student_ID") %>%
  mutate(class = ifelse(!is.na(correct_class), correct_class, class)) %>%
  select(-correct_class)

```

```{r}
#remove index column
df_StudentRecord <- df_StudentRecord %>% select(-1)
df_TitleInfo <- df_TitleInfo %>% select(-1)
df_StudentInfo <- df_StudentInfo %>% select(-1)

```

```{r}
summary(df_StudentRecord)
summary (df_TitleInfo)
summary (df_StudentInfo)
```

```{r}
# Convert time from timestamp to POSIXct
df_StudentRecord$time_change <- as.POSIXct(df_StudentRecord$time, origin="1970-01-01", tz="UTC")

df_StudentRecord <- df_StudentRecord %>%
  mutate(
    time_change = ymd_hms(time_change),
    date = as.Date(time_change),
    time = as_hms(format(time_change, "%H:%M:%S")),
    score = as.factor(score),
    timeconsume = as.numeric(timeconsume)
  ) 

df_TitleInfo <- df_TitleInfo %>%
  mutate (
    score = as.factor(score)
  )
```

```{r}
missing_students <- anti_join(df_StudentRecord, df_StudentInfo, by = "student_ID")

# Display the missing student IDs
missing_student_ids <- missing_students %>% select(student_ID) %>% distinct()
print(missing_student_ids)


unique(df_StudentRecord$state)

df_StudentRecord <- df_StudentRecord %>%
  filter (state != '�������')%>%
  filter (class != "class")
```

Based on the output, there is a significant number of 2,612 rows with the unexpected value. Hence these rows will be kept in the analysis and replaced with 0 (since there is no existing values of 0 too), however subsequent analysis in this exercise involving the timeconsume variable will treat these values as missing values. This is done in the following code chunk

```{r}
df_StudentRecord <- df_StudentRecord %>%
  mutate(timeconsume = ifelse(timeconsume %in% c("-", "--"), 0, timeconsume))
unique(df_StudentRecord$timeconsume)
```





```{r}

# Aggregate knowledge and sub_knowledge into lists
title_info_aggregated <- df_TitleInfo %>%
  group_by(title_ID, question_score) %>%
  summarise(knowledge_list = list(unique(knowledge)),
            sub_knowledge_list = list(unique(sub_knowledge)),
            .groups = 'drop')

# View the first few rows of the aggregated data to confirm it looks correct
head(title_info_aggregated)

```

```{r}
# Merge StudentInfo with SubmitRecord based on student_ID
merged_data <- merge(df_StudentRecord, df_StudentInfo, by = "student_ID")

# Merge TitleInfo with the already merged data based on title_ID
merged_data <- merge(merged_data, df_TitleInfo, by = "title_ID")

merged_data <- merged_data %>%
  rename(
    actual_score = score
  ) %>%
  mutate (actual_score = as.numeric(as.character(actual_score)))
```
### Based on point system for mastery.

If student get partially correct, award 1 point, if student get abosultely correct, award 2 points. When the student keep practicing the question, we assume he will be a master of the topic.

```{r}

merged_data <- merged_data %>%
  mutate(true_points = case_when(
    state == "Absolutely_Correct" ~ 2,
    state == "Partially_Correct" ~  actual_score /question_score ,
    TRUE ~ -1
  )) 

# Expand rows for questions with multiple knowledge groups
knowledge_expanded <- merged_data %>%
  separate_rows(knowledge, sep = ",") %>%
  mutate(knowledge = str_trim(knowledge))

# Identify students who have never gotten a title_ID Absolutely Correct
never_absolutely_correct <- knowledge_expanded %>%
  group_by(student_ID, title_ID, knowledge) %>%
  summarise(
    never_absolutely_correct = all(state != "Absolutely_Correct"),
    .groups = 'drop'
  ) %>%
  filter(never_absolutely_correct)

# Calculate knowledge mastery scores for each student
knowledge_mastery <- knowledge_expanded %>%
  group_by(student_ID, class, knowledge) %>%
  summarise(average_score = mean(true_points), .groups = 'drop') %>%
  left_join(df_StudentInfo %>% select(student_ID, sex, age, major), by = "student_ID") %>%
  mutate(age = as.character(age))

# Save processed datasets
saveRDS(merged_data, file = "merged_data.RDS")
saveRDS(knowledge_expanded, file = "knowledge_expanded.RDS")
saveRDS(never_absolutely_correct, file = "never_absolutely_correct.RDS")
saveRDS(knowledge_mastery, file = "knowledge_mastery.RDS")

```


```{r}
check_partially <- merged_data %>%
  filter (state == "Partially_Correct")

print(unique(check_partially$actual_score))
```


```{r}
#| echo: false
summary (merged_data)
```


## correct answering rate by student_id

```{r}


# Calculate the correct and error rates for each student across all questions
correct_and_error_rates_by_student <- merged_data %>%
  group_by(student_ID,title_ID) %>%
  summarise(
    Total_Attempts = n(),
    Absolutely_Correct_Count = sum(state == "Absolutely_Correct", na.rm = TRUE),
    Partially_Correct_Count = sum(state == "Partially_Correct", na.rm = TRUE),
    Error_Count = sum(grepl("Error", state), na.rm = TRUE),  # Summing all states that include 'Error'
    .groups = 'drop'
  ) %>%
  mutate(
    Absolutely_Correct_Rate = Absolutely_Correct_Count / Total_Attempts * 100,
    Partially_Correct_Rate = Partially_Correct_Count / Total_Attempts * 100,
    Error_Rate = Error_Count / Total_Attempts * 100
  ) %>%
  mutate(
    Absolutely_Correct_Rate = ifelse(is.na(Absolutely_Correct_Rate), 0, Absolutely_Correct_Rate),
    Partially_Correct_Rate = ifelse(is.na(Partially_Correct_Rate), 0, Partially_Correct_Rate),
    Error_Rate = ifelse(is.na(Error_Rate), 0, Error_Rate)
  )
```
```{r}
# View the results
summary(correct_and_error_rates_by_student)
```

##Scores for each student for each question

```{r}

# Convert 'actual_score' 
merged_data$actual_score <- as.numeric(as.character(merged_data$actual_score))

# Check for any conversion errors
sum(is.na(merged_data$actual_score))

# Calculate scores for each student for each question
scores_by_student_question <- merged_data %>%
  group_by(student_ID, title_ID) %>%
  summarise(
    Average_Score = mean(actual_score, na.rm = TRUE),  # Average score per question per student
    Max_Score = max(actual_score, na.rm = TRUE),       # Maximum score per question per student
    Min_Score = min(actual_score, na.rm = TRUE),       # Minimum score per question per student
    Median_Score = median(actual_score, na.rm = TRUE), # Median score per question per student
    IQR_Score = IQR(actual_score, na.rm = TRUE),       # Interquartile Range per question per student
    Total_Attempts = n(),                              # Total number of attempts per question per student
    .groups = 'drop'                                  
  )
```

```{r}
# View the results
summary(scores_by_student_question)
```



##Scores for each knowledge area per question
```{r}

# Calculate average scores for each knowledge area per question
knowledge_scores <- merged_data %>%
  group_by(student_ID, title_ID,knowledge,actual_score) %>%
  summarise(
    Average_Score = mean(actual_score, na.rm = TRUE),  # Average score per knowledge area per question
    Max_Score = max(actual_score, na.rm = TRUE),       # Maximum score per knowledge area per question
    Min_Score = min(actual_score, na.rm = TRUE),       # Minimum score per knowledge area per question
    Median_Score = median(actual_score, na.rm = TRUE), # Median score per knowledge area per question
    IQR_Score = IQR(actual_score, na.rm = TRUE),       # Interquartile Range per knowledge area per question
    Total_Attempts = n(),                              # Total number of attempts per knowledge area per question
    .groups = 'drop'                                   # Ensure the data is no longer grouped after summarization
  )
```
```{r}
# View the results
summary(knowledge_scores)

```

##Scores for each sub_knowledge area per question
```{r}
##Scores for each sub_knowledge area per question

sub_knowledge_scores <- merged_data %>%
  group_by(student_ID, title_ID,sub_knowledge) %>%
  summarise(
    Average_Score = mean(actual_score, na.rm = TRUE),  # Average score per knowledge area per question
    Max_Score = max(actual_score, na.rm = TRUE),       # Maximum score per knowledge area per question
    Min_Score = min(actual_score, na.rm = TRUE),       # Minimum score per knowledge area per question
    Median_Score = median(actual_score, na.rm = TRUE), # Median score per knowledge area per question
    IQR_Score = IQR(actual_score, na.rm = TRUE),       # Interquartile Range per knowledge area per question
    Total_Attempts = n(),                              # Total number of attempts per knowledge area per question
    .groups = 'drop'                                   # Ensure the data is no longer grouped after summarization
  )

```
```{r}
# View the results
summary(sub_knowledge_scores)

```


```{r}
# Ensure actual_score is numeric
merged_data$actual_score <- as.numeric(merged_data$actual_score)

# Convert necessary columns to factors if they are not numeric
merged_data$title_ID <- as.factor(merged_data$title_ID)
merged_data$state <- as.factor(merged_data$state)
merged_data$method <- as.factor(merged_data$method)

# Plot distributions
p1 <- ggplot(merged_data, aes(x = title_ID)) +
  geom_bar(fill = 'skyblue', color = 'black') +
  labs(title = 'Distribution of Title ID', x = 'Title ID', y = 'Frequency') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 6))

p2 <- ggplot(merged_data, aes(x = actual_score)) +
  geom_histogram(binwidth = 1, fill = 'skyblue', color = 'black') +
  labs(title = 'Distribution of Actual Scores', x = 'Actual Score', y = 'Frequency')

p3 <- ggplot(merged_data, aes(x = state)) +
  geom_bar(fill = 'skyblue', color = 'black') +
  labs(title = 'Distribution of State', x = 'State', y = 'Frequency') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 6))



# Combine the plots into one layout
p1+ p2 + p3 

```



Correct and Error Rates by Student

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)
library(scales)

# Assuming correct_and_error_rates_by_student is your dataset

# Convert to long format for plotting
rates_long <- correct_and_error_rates_by_student %>%
  pivot_longer(cols = c("Absolutely_Correct_Rate", "Partially_Correct_Rate", "Error_Rate"), 
               names_to = "rate_type", values_to = "rate")

# Create ggplot
p <- ggplot(rates_long, aes(x = title_ID, y = rate, fill = rate_type)) +
  geom_bar(stat = "identity", position = "fill") +
  labs(title = "Distribution of Correct, Partially Correct, and Error Rates by Question", 
       x = "Question ID", 
       y = "Percentile") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 8)) +
  scale_y_continuous(labels = percent) +  # Format y-axis labels as percentages
  scale_fill_manual(values = c("green", "yellow", "red"), 
                    labels = c("Absolutely Correct Rate", "Partially Correct Rate", "Error Rate"))

# Print the plot
print(p)


```

Visualize Scores for Each Student for Each Question



Visualize Scores for Each Knowledge Area per Question
```{r}

# Reorder title_ID based on knowledge
knowledge_scores <- knowledge_scores %>%
  mutate(title_ID = factor(title_ID, levels = unique(title_ID[order(knowledge)])))

# Create the box plot
p2 <- ggplot(knowledge_scores, aes(x = title_ID, y = actual_score, fill = knowledge)) +
  geom_boxplot() +
  labs(title = "Score Distribution per Knowledge Area per Question", x = "Question ID", y = "Score") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_fill_brewer(palette = "Set3")

# Print plot
print(p2)


```

static parallel coordinates plot 
```{r}


```






```{r}
# Heatmap for Average Scores per knowledge area per question
p3 <- ggplot(knowledge_scores, aes(x = title_ID, y = knowledge, fill = Average_Score)) +
  geom_tile() +
  labs(title = "Heatmap of Average Scores per Knowledge Area per Question", x = "Question ID", y = "Knowledge Area") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 8),  # Adjust the size of x-axis text for better readability
        plot.title = element_text(hjust = 0.5)) +  # Center the plot title
  scale_fill_gradient(low = "green", high = "blue", limits = c(0, 3), breaks = c(0, 1, 2, 3), labels = c("0", "1", "2", "3"))

# Print plot
print(p3)


```
